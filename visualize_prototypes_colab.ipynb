{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prototype Visualization for MProtoNet3D - Google Colab\n",
        "\n",
        "This notebook visualizes the learned prototypes from your trained brain tumor segmentation model.\n",
        "\n",
        "**Steps:**\n",
        "1. Mount Google Drive (where your model is saved)\n",
        "2. Clone GitHub repository\n",
        "3. Download preprocessed data from S3\n",
        "4. Run prototype visualization\n",
        "5. Save visualizations to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# Enable memory growth\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set path to your trained model in Google Drive\n",
        "MODEL_PATH = '/content/drive/MyDrive/brain_tumor_checkpoints/best_model_YYYYMMDD-HHMMSS.keras'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/brain_tumor_checkpoints/prototype_visualizations'\n",
        "\n",
        "print(f\"Model will be loaded from: {MODEL_PATH}\")\n",
        "print(f\"Visualizations will be saved to: {OUTPUT_DIR}\")\n",
        "print(\"\\nâš ï¸ Update MODEL_PATH above with your actual model filename!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install h5py numpy tensorflow keras matplotlib awscli boto3 tqdm -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Clone GitHub Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "GITHUB_REPO_URL = \"https://github.com/dariamarc/brainTumorSurvival.git\"\n",
        "repo_name = GITHUB_REPO_URL.split('/')[-1].replace('.git', '')\n",
        "\n",
        "print(f\"Cloning repository: {GITHUB_REPO_URL}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Change to /content first\n",
        "os.chdir('/content')\n",
        "\n",
        "# Remove if exists\n",
        "if os.path.exists(f'/content/{repo_name}'):\n",
        "    !rm -rf /content/{repo_name}\n",
        "    print(f\"Removed existing directory: {repo_name}\")\n",
        "\n",
        "# Clone\n",
        "!git clone {GITHUB_REPO_URL}\n",
        "\n",
        "# Change to repo directory\n",
        "os.chdir(f'/content/{repo_name}')\n",
        "print(f\"\\nâœ“ Changed to directory: {os.getcwd()}\")\n",
        "\n",
        "# List files\n",
        "print(\"\\nRepository contents:\")\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Configure AWS Credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "print(\"Configuring AWS credentials...\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "try:\n",
        "    os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "    os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "    print(\"âœ“ AWS credentials loaded from Colab Secrets\")\n",
        "except Exception as e:\n",
        "    print(\"âœ— Error loading AWS credentials\")\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"\\nPlease add AWS credentials to Colab Secrets (ðŸ”‘ icon)\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Download Preprocessed Data from S3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# UPDATE WITH YOUR S3 DETAILS\n",
        "# ============================================================================\n",
        "S3_BUCKET = 'your-brats2020-data'\n",
        "S3_PATH = 'preprocessed_data'\n",
        "AWS_REGION = 'eu-central-1'\n",
        "# ============================================================================\n",
        "\n",
        "LOCAL_DATA_PATH = '/content/brainTumorData_preprocessed'\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DOWNLOADING PREPROCESSED DATA FROM S3\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "os.environ['AWS_DEFAULT_REGION'] = AWS_REGION\n",
        "\n",
        "print(f\"Source: s3://{S3_BUCKET}/{S3_PATH}\")\n",
        "print(f\"Destination: {LOCAL_DATA_PATH}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "!mkdir -p {LOCAL_DATA_PATH}\n",
        "!aws s3 sync s3://{S3_BUCKET}/{S3_PATH} {LOCAL_DATA_PATH}\n",
        "\n",
        "# Verify\n",
        "if os.path.exists(LOCAL_DATA_PATH):\n",
        "    file_count = sum([len(files) for r, d, files in os.walk(LOCAL_DATA_PATH)])\n",
        "    print(f\"\\nâœ“ Downloaded {file_count:,} files\")\n",
        "    print(f\"âœ“ Data ready at: {LOCAL_DATA_PATH}\")\n",
        "else:\n",
        "    print(\"\\nâœ— Download failed!\")\n",
        "    raise FileNotFoundError(f\"Data not found at {LOCAL_DATA_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Ensure repository is in Python path\n",
        "repo_dir = f'/content/{repo_name}'\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.insert(0, repo_dir)\n",
        "\n",
        "# Import modules\n",
        "from model import MProtoNet3D_Segmentation_Keras\n",
        "from losses import CombinedLoss\n",
        "from data_generator import MRIDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"âœ“ All modules imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Load Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Loading model from: {MODEL_PATH}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "model = tf.keras.models.load_model(\n",
        "    MODEL_PATH,\n",
        "    custom_objects={'CombinedLoss': CombinedLoss}\n",
        ")\n",
        "\n",
        "print(\"âœ“ Model loaded successfully!\")\n",
        "print(f\"\\nModel summary:\")\n",
        "print(f\"  - Number of prototypes: {model.num_prototypes}\")\n",
        "print(f\"  - Number of classes: {model.num_classes}\")\n",
        "print(f\"  - Prototypes per class: {model.num_prototypes_per_class}\")\n",
        "print(f\"  - Prototype shape: {model.prototype_shape_tuple}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Extract Prototype Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prototype_vectors = model.prototype_vectors.numpy()\n",
        "\n",
        "print(\"Prototype Information:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Prototype vectors shape: {prototype_vectors.shape}\")\n",
        "print(f\"Number of prototypes: {prototype_vectors.shape[0]}\")\n",
        "print(f\"Feature dimensions: {prototype_vectors.shape[1]}\")\n",
        "\n",
        "# Show class assignments\n",
        "print(f\"\\nPrototype class assignments:\")\n",
        "class_names = ['GD-enhancing tumor (ET)', 'Peritumoral edema (ED)', 'Necrotic core (NCR/NET)']\n",
        "for i in range(model.num_prototypes):\n",
        "    class_idx = i // model.num_prototypes_per_class\n",
        "    print(f\"  Prototype {i:2d} -> Class {class_idx} ({class_names[class_idx]})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Create Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Creating data generator...\")\n",
        "\n",
        "data_generator = MRIDataGenerator(\n",
        "    LOCAL_DATA_PATH,\n",
        "    batch_size=1,\n",
        "    num_slices=96,\n",
        "    num_volumes=369,\n",
        "    split_ratio=0.2,\n",
        "    subset='train',\n",
        "    shuffle=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Data generator created\")\n",
        "print(f\"  - Training volumes: {len(data_generator.indices)}\")\n",
        "print(f\"  - Batches: {len(data_generator)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Find Closest Patches to Each Prototype\n",
        "\n",
        "This searches through training data to find image patches that most strongly activate each prototype."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_SAMPLES_TO_CHECK = 50  # Adjust based on how thorough you want the search\n",
        "\n",
        "print(f\"Searching through {NUM_SAMPLES_TO_CHECK} volumes for closest prototype matches...\")\n",
        "print(\"This may take 5-10 minutes...\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Create feature extractor\n",
        "feature_extractor = tf.keras.Model(\n",
        "    inputs=model.input,\n",
        "    outputs=model.add_ons.output\n",
        ")\n",
        "\n",
        "num_prototypes = prototype_vectors.shape[0]\n",
        "\n",
        "# Track best matches for each prototype\n",
        "best_matches = {i: {\n",
        "    'activation': -np.inf,\n",
        "    'volume_idx': None,\n",
        "    'slice_idx': None,\n",
        "    'location': None,\n",
        "    'image_patch': None,\n",
        "    'mask_patch': None\n",
        "} for i in range(num_prototypes)}\n",
        "\n",
        "# Iterate through data\n",
        "for sample_idx in tqdm(range(min(NUM_SAMPLES_TO_CHECK, len(data_generator)))):\n",
        "    batch_x, batch_y = data_generator[sample_idx]\n",
        "    \n",
        "    # Extract features\n",
        "    features = feature_extractor.predict(batch_x, verbose=0)\n",
        "    \n",
        "    # Compute prototype activations\n",
        "    if model.f_dist == 'l2':\n",
        "        distances = model.l2_convolution_3D(features).numpy()\n",
        "        similarities = model.distance_2_similarity(distances).numpy()\n",
        "    else:\n",
        "        similarities = model.cosine_convolution_3D(features).numpy()\n",
        "    \n",
        "    # For each prototype, check if this is the best activation\n",
        "    for proto_idx in range(num_prototypes):\n",
        "        proto_similarities = similarities[0, :, :, :, proto_idx]\n",
        "        max_activation = np.max(proto_similarities)\n",
        "        \n",
        "        if max_activation > best_matches[proto_idx]['activation']:\n",
        "            max_loc = np.unravel_index(np.argmax(proto_similarities), proto_similarities.shape)\n",
        "            d, h, w = max_loc\n",
        "            \n",
        "            # Extract patch\n",
        "            patch_size = 16\n",
        "            h_start = max(0, h - patch_size // 2)\n",
        "            h_end = min(batch_x.shape[2], h + patch_size // 2)\n",
        "            w_start = max(0, w - patch_size // 2)\n",
        "            w_end = min(batch_x.shape[3], w + patch_size // 2)\n",
        "            \n",
        "            image_patch = batch_x[0, d, h_start:h_end, w_start:w_end, :]\n",
        "            if len(batch_y.shape) == 5:\n",
        "                mask_patch = batch_y[0, d, h_start:h_end, w_start:w_end, :]\n",
        "            else:\n",
        "                mask_patch = batch_y[0, d, h_start:h_end, w_start:w_end]\n",
        "            \n",
        "            best_matches[proto_idx] = {\n",
        "                'activation': max_activation,\n",
        "                'volume_idx': data_generator.volume_ids[data_generator.indices[sample_idx]],\n",
        "                'slice_idx': d,\n",
        "                'location': (h, w),\n",
        "                'image_patch': image_patch,\n",
        "                'mask_patch': mask_patch\n",
        "            }\n",
        "\n",
        "print(\"\\nâœ“ Search complete!\")\n",
        "print(f\"Found best matches for all {num_prototypes} prototypes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Visualize Prototypes by Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p {OUTPUT_DIR}\n",
        "\n",
        "modality_names = ['T1', 'T1ce', 'T2', 'FLAIR']\n",
        "\n",
        "for class_idx in range(model.num_classes):\n",
        "    print(f\"Visualizing prototypes for class {class_idx}: {class_names[class_idx]}\")\n",
        "    \n",
        "    start_proto = class_idx * model.num_prototypes_per_class\n",
        "    end_proto = start_proto + model.num_prototypes_per_class\n",
        "    \n",
        "    fig, axes = plt.subplots(model.num_prototypes_per_class, 5, \n",
        "                             figsize=(25, 5 * model.num_prototypes_per_class))\n",
        "    \n",
        "    for local_idx, proto_idx in enumerate(range(start_proto, end_proto)):\n",
        "        match = best_matches[proto_idx]\n",
        "        \n",
        "        # Column 0: Info\n",
        "        axes[local_idx, 0].text(0.5, 0.5,\n",
        "            f\"Prototype {proto_idx}\\n\"\n",
        "            f\"Class: {class_idx}\\n\"\n",
        "            f\"Activation: {match['activation']:.4f}\\n\"\n",
        "            f\"Volume: {match['volume_idx']}\\n\"\n",
        "            f\"Slice: {match['slice_idx']}\\n\"\n",
        "            f\"Location: {match['location']}\",\n",
        "            ha='center', va='center', fontsize=10,\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "        axes[local_idx, 0].axis('off')\n",
        "        \n",
        "        # Columns 1-4: Modalities\n",
        "        if match['image_patch'] is not None:\n",
        "            for mod_idx in range(4):\n",
        "                axes[local_idx, mod_idx + 1].imshow(match['image_patch'][:, :, mod_idx], cmap='gray')\n",
        "                axes[local_idx, mod_idx + 1].set_title(f\"{modality_names[mod_idx]}\", fontsize=10)\n",
        "                axes[local_idx, mod_idx + 1].axis('off')\n",
        "    \n",
        "    plt.suptitle(f\"Learned Prototypes for Class {class_idx}: {class_names[class_idx]}\",\n",
        "                 fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{OUTPUT_DIR}/prototypes_class_{class_idx}.png\", dpi=300, bbox_inches='tight')\n",
        "    print(f\"  âœ“ Saved: prototypes_class_{class_idx}.png\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Visualize Activation Maps with Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for class_idx in range(model.num_classes):\n",
        "    start_proto = class_idx * model.num_prototypes_per_class\n",
        "    end_proto = start_proto + model.num_prototypes_per_class\n",
        "    \n",
        "    fig, axes = plt.subplots(2, model.num_prototypes_per_class, \n",
        "                             figsize=(model.num_prototypes_per_class * 4, 8))\n",
        "    \n",
        "    for local_idx, proto_idx in enumerate(range(start_proto, end_proto)):\n",
        "        match = best_matches[proto_idx]\n",
        "        \n",
        "        if match['image_patch'] is not None:\n",
        "            # Show T1ce image\n",
        "            axes[0, local_idx].imshow(match['image_patch'][:, :, 1], cmap='gray')\n",
        "            axes[0, local_idx].set_title(f\"Proto {proto_idx}\\nT1ce\", fontsize=10)\n",
        "            axes[0, local_idx].axis('off')\n",
        "            \n",
        "            # Show with mask overlay\n",
        "            if len(match['mask_patch'].shape) == 3:\n",
        "                mask_vis = np.argmax(match['mask_patch'], axis=-1)\n",
        "            else:\n",
        "                mask_vis = match['mask_patch']\n",
        "            \n",
        "            axes[1, local_idx].imshow(match['image_patch'][:, :, 1], cmap='gray')\n",
        "            axes[1, local_idx].imshow(mask_vis, cmap='jet', alpha=0.5)\n",
        "            axes[1, local_idx].set_title(f\"With Mask\\nAct: {match['activation']:.3f}\", fontsize=10)\n",
        "            axes[1, local_idx].axis('off')\n",
        "    \n",
        "    plt.suptitle(f\"Prototype Activation Maps - {class_names[class_idx]}\",\n",
        "                 fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{OUTPUT_DIR}/activation_maps_class_{class_idx}.png\", dpi=300, bbox_inches='tight')\n",
        "    print(f\"âœ“ Saved: activation_maps_class_{class_idx}.png\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Visualize Prototype Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute statistics\n",
        "proto_norms = np.linalg.norm(prototype_vectors.reshape(num_prototypes, -1), axis=1)\n",
        "proto_flat = prototype_vectors.reshape(num_prototypes, -1)\n",
        "similarities = np.dot(proto_flat, proto_flat.T) / (\n",
        "    np.outer(proto_norms, proto_norms) + 1e-8\n",
        ")\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Plot 1: Norms\n",
        "axes[0].bar(range(num_prototypes), proto_norms)\n",
        "axes[0].set_xlabel('Prototype Index')\n",
        "axes[0].set_ylabel('L2 Norm')\n",
        "axes[0].set_title('Prototype Vector Magnitudes')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Activations\n",
        "activations = [best_matches[i]['activation'] for i in range(num_prototypes)]\n",
        "axes[1].bar(range(num_prototypes), activations)\n",
        "axes[1].set_xlabel('Prototype Index')\n",
        "axes[1].set_ylabel('Max Activation')\n",
        "axes[1].set_title('Best Activation Strength per Prototype')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Similarity matrix\n",
        "im = axes[2].imshow(similarities, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "axes[2].set_xlabel('Prototype Index')\n",
        "axes[2].set_ylabel('Prototype Index')\n",
        "axes[2].set_title('Prototype Similarity Matrix')\n",
        "plt.colorbar(im, ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUTPUT_DIR}/prototype_statistics.png\", dpi=300, bbox_inches='tight')\n",
        "print(\"âœ“ Saved: prototype_statistics.png\")\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 15: Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"âœ“ PROTOTYPE VISUALIZATION COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nAll visualizations saved to Google Drive:\")\n",
        "print(f\"  {OUTPUT_DIR}/\")\n",
        "print(f\"\\nFiles created:\")\n",
        "print(f\"  - prototypes_class_0.png (GD-enhancing tumor)\")\n",
        "print(f\"  - prototypes_class_1.png (Peritumoral edema)\")\n",
        "print(f\"  - prototypes_class_2.png (Necrotic core)\")\n",
        "print(f\"  - activation_maps_class_*.png (Activation heatmaps)\")\n",
        "print(f\"  - prototype_statistics.png (Statistics and similarities)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# List files\n",
        "!ls -lh {OUTPUT_DIR}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "visualize_prototypes_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
