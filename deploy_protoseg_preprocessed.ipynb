{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 3D Brain Tumor Segmentation with ProtoSeg3D - AWS S3 Deployment\n\nThis notebook deploys your **interpretable** 3D brain tumor segmentation network (ProtoSeg3D) from GitHub with data from AWS S3.\n\n**What is ProtoSeg3D?**\n- Prototype-based segmentation model\n- Interpretable: Decisions based on learned prototypes\n- Uses ASPP 3D with isotropic pooling for multi-scale context\n- Diversity loss based on Jeffrey's divergence (graph-compatible)\n- Multi-step training protocol (+3-5% mIoU improvement)\n\n**Quick Setup:**\n1. Upload this notebook to Google Colab\n2. Go to Runtime ‚Üí Change runtime type ‚Üí Select **GPU (T4 or better)**\n3. Add AWS credentials to Colab Secrets (üîë icon on left)\n4. Update GitHub repository URL and S3 bucket details\n5. Choose training mode: Single-phase (faster) or Multi-step (better results)\n6. Run all cells\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU and System Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SYSTEM INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"\\nGPU Devices: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Enable memory growth to prevent OOM errors\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"\\n‚úì Memory growth enabled for {len(gpus)} GPU(s)\")\n",
    "        print(f\"‚úì GPU: {gpus[0].name}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error enabling memory growth: {e}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: No GPU detected! Please enable GPU in Runtime ‚Üí Change runtime type\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Check Available Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"AVAILABLE RESOURCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüì¶ Disk Space:\")\n",
    "!df -h /content | grep -E 'Filesystem|/content'\n",
    "\n",
    "print(\"\\nüß† RAM:\")\n",
    "!free -h | grep -E 'total|Mem'\n",
    "\n",
    "print(\"\\nüéÆ GPU Memory:\")\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Note: Your ~4 GB preprocessed dataset will use disk space, not RAM\")\n",
    "print(\"Only one batch (~200 MB) is loaded in RAM at a time\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Silent installation - remove %%capture to see output\n",
    "!pip install h5py numpy tensorflow keras matplotlib awscli boto3 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Clone GitHub Repository\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT: Update the repository URL below with your GitHub repository!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# UPDATE THIS WITH YOUR GITHUB REPOSITORY URL\n",
    "# ============================================================================\n",
    "GITHUB_REPO_URL = \"https://github.com/dariamarc/brainTumorSurvival.git\"\n",
    "# ============================================================================\n",
    "\n",
    "# Repository name (extracted from URL)\n",
    "repo_name = GITHUB_REPO_URL.split('/')[-1].replace('.git', '')\n",
    "\n",
    "print(f\"Cloning repository: {GITHUB_REPO_URL}\")\n",
    "print(f\"Repository name: {repo_name}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# IMPORTANT: Change to /content first to avoid directory issues\n",
    "os.chdir('/content')\n",
    "print(\"Changed to /content directory\")\n",
    "\n",
    "# Remove if exists (for re-running)\n",
    "if os.path.exists(f'/content/{repo_name}'):\n",
    "    !rm -rf /content/{repo_name}\n",
    "    print(f\"Removed existing directory: {repo_name}\")\n",
    "\n",
    "# Clone the repository\n",
    "!git clone {GITHUB_REPO_URL}\n",
    "\n",
    "# Change to repository directory\n",
    "os.chdir(f'/content/{repo_name}')\n",
    "print(f\"\\n‚úì Changed to directory: {os.getcwd()}\")\n",
    "\n",
    "# List files to verify\n",
    "print(\"\\nRepository contents:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Required Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_files = ['model_protoseg.py', 'data_generator.py', 'losses_protoseg.py']\n",
    "optional_files = ['main_protoseg.py', 'main_protoseg_multistep.py']\n",
    "\n",
    "print(\"Checking required files for ProtoSeg3D...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_present = True\n",
    "for file in required_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"‚úì {file} - Found\")\n",
    "    else:\n",
    "        print(f\"‚úó {file} - MISSING\")\n",
    "        all_present = False\n",
    "\n",
    "print(\"\\nChecking optional files...\")\n",
    "for file in optional_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"‚úì {file} - Found\")\n",
    "    else:\n",
    "        print(f\"- {file} - Not present (optional)\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "if all_present:\n",
    "    print(\"‚úì All required files present! Ready to proceed.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: Some required files are missing!\")\n",
    "    print(\"Please check your repository structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Configure AWS Credentials\n",
    "\n",
    "**IMPORTANT SECURITY STEPS:**\n",
    "\n",
    "1. Click the **üîë Secrets** icon in the left sidebar\n",
    "2. Add these secrets:\n",
    "   - Name: `AWS_ACCESS_KEY_ID`, Value: Your AWS access key\n",
    "   - Name: `AWS_SECRET_ACCESS_KEY`, Value: Your AWS secret key\n",
    "3. Enable \"Notebook access\" for both secrets\n",
    "\n",
    "**Never hardcode credentials in notebooks!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "print(\"Configuring AWS credentials...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    # Get credentials from Colab Secrets\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('AWS_ACCESS_KEY_ID')\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "    print(\"‚úì AWS credentials loaded from Colab Secrets\")\n",
    "    print(\"‚úì Access Key ID: \" + os.environ['AWS_ACCESS_KEY_ID'][:8] + \"...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚úó Error loading AWS credentials from Colab Secrets\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nPlease add AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY to Colab Secrets (üîë icon)\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 7: Download Preprocessed Dataset from AWS S3\n\n**‚ö†Ô∏è UPDATE YOUR S3 BUCKET DETAILS BELOW**\n\nThis will download your preprocessed dataset (128√ó160√ó192) to Colab's local storage.  \n**Benefits:**\n- Faster download: ~4 GB instead of ~8 GB\n- No preprocessing needed: Ready to train immediately\n- Center-cropped only (no resizing): Preserves original resolution\n- Saves 15-20 minutes of preprocessing time\n\n**Estimated download time: 5-8 minutes**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# UPDATE THESE WITH YOUR S3 DETAILS\n# ============================================================================\nS3_BUCKET = 'your-brats2020-data'           # Your S3 bucket name\nS3_PATH = 'preprocessed_data'               # Path to PREPROCESSED data in S3\nAWS_REGION = 'eu-central-1'                 # Your bucket's region\n# ============================================================================\n\nLOCAL_PATH = '/content/brainTumorData_preprocessed'\n\nprint(\"=\" * 60)\nprint(\"DOWNLOADING PREPROCESSED DATASET FROM AWS S3\")\nprint(\"=\" * 60)\n\n# Set AWS region\nos.environ['AWS_DEFAULT_REGION'] = AWS_REGION\n\nprint(f\"\\nSource: s3://{S3_BUCKET}/{S3_PATH}\")\nprint(f\"Destination: {LOCAL_PATH}\")\nprint(f\"Region: {AWS_REGION}\")\nprint(f\"Dataset: Preprocessed (128√ó160√ó192, center-cropped)\")\nprint(f\"Dataset size: ~4 GB\")\nprint(f\"Estimated time: 5-8 minutes\")\nprint(\"-\" * 60)\nprint(\"Starting download...\\n\")\n\n# Create local directory\n!mkdir -p {LOCAL_PATH}\n\n# Download preprocessed data using AWS CLI sync (shows progress)\n!aws s3 sync s3://{S3_BUCKET}/{S3_PATH} {LOCAL_PATH}\n\n# Verify download\nprint(\"\\n\" + \"=\" * 60)\nif os.path.exists(LOCAL_PATH):\n    # Count files\n    file_count = sum([len(files) for r, d, files in os.walk(LOCAL_PATH)])\n\n    # Calculate size\n    total_size = sum(\n        os.path.getsize(os.path.join(dirpath, filename))\n        for dirpath, dirnames, filenames in os.walk(LOCAL_PATH)\n        for filename in filenames\n    ) / (1024**3)  # Convert to GB\n\n    print(\"‚úì DOWNLOAD COMPLETE!\")\n    print(\"=\" * 60)\n    print(f\"Location: {LOCAL_PATH}\")\n    print(f\"Files downloaded: {file_count:,}\")\n    print(f\"Total size: {total_size:.2f} GB\")\n    print(f\"Expected files: 47,232 (369 volumes √ó 128 slices)\")\n\n    # Show sample files\n    print(\"\\nSample files:\")\n    !ls {LOCAL_PATH} | head -10\n\n    # Check disk space after download\n    print(\"\\nüì¶ Disk Usage After Download:\")\n    !df -h /content | grep -E 'Filesystem|/content'\n\n    # Set data path to preprocessed directory\n    DATA_PATH = LOCAL_PATH\n    print(f\"\\n‚úì DATA_PATH set to: {DATA_PATH}\")\n    print(\"‚úì Data is already preprocessed - ready to train!\")\nelse:\n    print(\"‚úó DOWNLOAD FAILED!\")\n    print(\"Please check:\")\n    print(\"  1. S3 bucket name is correct\")\n    print(\"  2. S3 path is correct (should be 'preprocessed_data')\")\n    print(\"  3. AWS credentials have read permissions\")\n    print(\"  4. AWS region is correct\")\n    raise FileNotFoundError(f\"Data not found at {LOCAL_PATH}\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\n\n# Ensure repository is in Python path\nrepo_dir = f'/content/{repo_name}'\nif repo_dir not in sys.path:\n    sys.path.insert(0, repo_dir)\n\nprint(f\"Python path includes: {repo_dir}\")\nprint(f\"Working directory: {os.getcwd()}\")\nprint(\"-\" * 60)\n\n# Import your modules\ntry:\n    from model_protoseg import ProtoSeg3D\n    from data_generator import MRIDataGenerator\n    from losses_protoseg import compute_diversity_loss\n    from tensorflow import keras\n    import numpy as np\n\n    print(\"‚úì All ProtoSeg3D modules imported successfully!\")\n    print(\"‚úì Diversity loss is graph-compatible (@tf.function)\")\n    print(\"‚úì Supports similarities from distances (via activation functions)\")\nexcept ImportError as e:\n    print(f\"‚úó Import error: {e}\")\n    print(\"\\nDebugging info:\")\n    print(\"Files in repository:\")\n    !ls -la\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Training Mode Selection\n",
    "\n",
    "**Choose your training mode:**\n",
    "\n",
    "### Option 1: Single-Phase Training (Faster)\n",
    "- Trains all components together from start\n",
    "- Estimated time: ~10-12 hours\n",
    "- Expected mIoU: 0.58-0.63\n",
    "\n",
    "### Option 2: Multi-Step Training (Better Results) ‚≠ê RECOMMENDED\n",
    "- Phase 1: Warmup (freeze encoder, train ASPP + prototypes)\n",
    "- Phase 2: Joint training (train all except FC layer)\n",
    "- Phase 3-4: Fine-tuning (train FC layer only)\n",
    "- Estimated time: ~14 hours\n",
    "- Expected mIoU: 0.62-0.68 (+3-5% improvement)\n",
    "- Better prototype quality and interpretability\n",
    "\n",
    "**Set the TRAINING_MODE below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHOOSE YOUR TRAINING MODE\n",
    "# ============================================================================\n",
    "TRAINING_MODE = \"multi-step\"  # Options: \"single-phase\" or \"multi-step\"\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING MODE SELECTION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Selected mode: {TRAINING_MODE.upper()}\")\n",
    "\n",
    "if TRAINING_MODE == \"single-phase\":\n",
    "    print(\"\\n‚úì Single-phase training selected\")\n",
    "    print(\"  - Trains all components together\")\n",
    "    print(\"  - Estimated time: ~10-12 hours\")\n",
    "    print(\"  - Expected mIoU: 0.58-0.63\")\n",
    "elif TRAINING_MODE == \"multi-step\":\n",
    "    print(\"\\n‚úì Multi-step training selected (RECOMMENDED)\")\n",
    "    print(\"  - Phase 1: Warmup (30k steps)\")\n",
    "    print(\"  - Phase 2: Joint training (30k steps)\")\n",
    "    print(\"  - Phase 3-4: Fine-tuning (2k steps each)\")\n",
    "    print(\"  - Estimated time: ~14 hours\")\n",
    "    print(\"  - Expected mIoU: 0.62-0.68 (+3-5% improvement)\")\n",
    "    print(\"  - Better prototype quality\")\n",
    "else:\n",
    "    raise ValueError(f\"Invalid TRAINING_MODE: {TRAINING_MODE}. Use 'single-phase' or 'multi-step'\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Training Configuration\n",
    "\n",
    "Adjust these parameters based on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# TRAINING CONFIGURATION - ADJUST AS NEEDED\n# ============================================================================\n\n# Data configuration\nBATCH_SIZE = 2          # Batch size (2 recommended for ProtoSeg3D)\nSPLIT_RATIO = 0.2       # 20% for validation\nRANDOM_STATE = 42\nNUM_VOLUMES = 369       # Total number of volumes\n\n# Volume dimensions (PREPROCESSED DATA - center-cropped only)\nD = 128                 # Depth (number of slices)\nH = 160                 # Height\nW = 192                 # Width\nC = 4                   # Channels (FLAIR, T1, T1ce, T2)\n\n# Model configuration\nNUM_CLASSES = 4         # Background + 3 tumor classes\nNUM_PROTOTYPES_PER_CLASS = 7\nPROTOTYPE_DIM = 128\nASPP_OUT_CHANNELS = 128  # Updated to match current architecture\n\n# Diversity loss configuration\nUSE_DIVERSITY_LOSS = True   # Now graph-compatible with @tf.function\nLAMBDA_J = 0.25             # Diversity loss weight\n\n# Single-phase training settings\nSINGLE_PHASE_EPOCHS = 100\nSINGLE_PHASE_LR = 0.0001\n\n# Multi-step training settings\nWARMUP_STEPS = 30000\nJOINT_STEPS = 30000\nFINETUNE_STEPS = 2000\nWARMUP_LR = 2.5e-4\nJOINT_LR = 1.3e-4       # Average of backbone (2.5e-5) and other (2.5e-4)\nFINETUNE_LR = 1e-5\n\n# ============================================================================\n\nINPUT_SHAPE = (D, H, W, C)\n\nprint(\"=\" * 60)\nprint(\"TRAINING CONFIGURATION\")\nprint(\"=\" * 60)\nprint(f\"Data path: {DATA_PATH}\")\nprint(f\"Input shape: {INPUT_SHAPE}\")\nprint(f\"Number of classes: {NUM_CLASSES}\")\nprint(f\"Prototypes per class: {NUM_PROTOTYPES_PER_CLASS}\")\nprint(f\"Total prototypes: {NUM_PROTOTYPES_PER_CLASS * NUM_CLASSES}\")\nprint(f\"Prototype dimension: {PROTOTYPE_DIM}\")\nprint(f\"ASPP output channels: {ASPP_OUT_CHANNELS}\")\nprint(f\"Batch size: {BATCH_SIZE}\")\nprint(f\"Total volumes: {NUM_VOLUMES}\")\nprint(f\"Train/Val split: {int((1-SPLIT_RATIO)*100)}% / {int(SPLIT_RATIO*100)}%\")\n\nif USE_DIVERSITY_LOSS:\n    print(f\"\\n‚úì Diversity loss ENABLED (Œª_J = {LAMBDA_J})\")\n    print(\"  ‚úì Graph-compatible implementation with @tf.function\")\nelse:\n    print(f\"\\n‚úó Diversity loss DISABLED\")\n\nif TRAINING_MODE == \"single-phase\":\n    print(f\"\\nSingle-phase settings:\")\n    print(f\"  - Epochs: {SINGLE_PHASE_EPOCHS}\")\n    print(f\"  - Learning rate: {SINGLE_PHASE_LR}\")\nelse:\n    # Convert steps to epochs\n    samples_per_epoch = int(NUM_VOLUMES * (1 - SPLIT_RATIO))\n    warmup_epochs = max(1, WARMUP_STEPS * BATCH_SIZE // samples_per_epoch)\n    joint_epochs = max(1, JOINT_STEPS * BATCH_SIZE // samples_per_epoch)\n    finetune_epochs = max(1, FINETUNE_STEPS * BATCH_SIZE // samples_per_epoch)\n    \n    print(f\"\\nMulti-step settings:\")\n    print(f\"  - Warmup: {WARMUP_STEPS} steps (~{warmup_epochs} epochs), LR={WARMUP_LR}\")\n    print(f\"  - Joint: {JOINT_STEPS} steps (~{joint_epochs} epochs), LR={JOINT_LR}\")\n    print(f\"  - Fine-tune: {FINETUNE_STEPS} steps (~{finetune_epochs} epochs), LR={FINETUNE_LR}\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Create Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating data generators...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "train_generator = MRIDataGenerator(\n",
    "    DATA_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_slices=D,\n",
    "    num_volumes=NUM_VOLUMES,\n",
    "    split_ratio=SPLIT_RATIO,\n",
    "    subset='train',\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "validation_generator = MRIDataGenerator(\n",
    "    DATA_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_slices=D,\n",
    "    num_volumes=NUM_VOLUMES,\n",
    "    split_ratio=SPLIT_RATIO,\n",
    "    subset='val',\n",
    "    shuffle=False,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Training batches: {len(train_generator)}\")\n",
    "print(f\"‚úì Validation batches: {len(validation_generator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Build and Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Building ProtoSeg3D model...\")\nprint(\"-\" * 60)\n\n# Build the ProtoSeg3D model\nmodel = ProtoSeg3D(\n    in_size=INPUT_SHAPE,\n    num_classes=NUM_CLASSES,\n    num_prototypes_per_class=NUM_PROTOTYPES_PER_CLASS,\n    prototype_dim=PROTOTYPE_DIM,\n    features='resnet50_ri',\n    f_dist='l2',\n    prototype_activation_function='log',\n    aspp_out_channels=ASPP_OUT_CHANNELS\n)\n\nprint(\"‚úì Model architecture created!\")\nprint(f\"  - Encoder: Isotropic pooling (2√ó2√ó2)\")\nprint(f\"  - ASPP: 128 channels, rates [1, 2, 4, 8]\")\nprint(f\"  - Prototype dimension: {PROTOTYPE_DIM}\")\n\n# Setup optimizer and loss\nif TRAINING_MODE == \"single-phase\":\n    optimizer = keras.optimizers.Adam(learning_rate=SINGLE_PHASE_LR)\nelse:\n    optimizer = keras.optimizers.Adam(learning_rate=WARMUP_LR)\n\nloss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n\n# Compile model\nmodel.compile(\n    optimizer=optimizer,\n    loss=loss_fn,\n    metrics=[\n        keras.metrics.MeanIoU(num_classes=NUM_CLASSES, name='mean_iou'),\n        keras.metrics.CategoricalAccuracy(name='accuracy')\n    ]\n)\n\nprint(\"‚úì Model compiled successfully!\")\n\n# Enable diversity loss if requested\nif USE_DIVERSITY_LOSS:\n    model.enable_diversity_loss(lambda_j=LAMBDA_J)\n    print(f\"\\n‚úì Diversity loss enabled (Œª_J = {LAMBDA_J})\")\n    print(\"  ‚úì Graph-compatible with @tf.function\")\n    print(\"  ‚úì Works with prototype similarities\")\n\nprint(\"\\nLoss function: Categorical Cross-Entropy (from logits)\")\nif USE_DIVERSITY_LOSS:\n    print(f\"              + Jeffrey's Divergence Diversity Loss (weight={LAMBDA_J})\")\nprint(\"\\nMetrics tracked:\")\nprint(\"  - Mean IoU (primary metric for segmentation)\")\nprint(\"  - Categorical Accuracy (overall voxel correctness)\")\n\n# Display prototype information\nproto_info = model.get_prototype_info()\nprint(\"\\n\" + \"=\" * 60)\nprint(\"PROTOTYPE INFORMATION\")\nprint(\"=\" * 60)\nprint(f\"Total prototypes: {proto_info['num_prototypes']}\")\nprint(f\"Prototypes per class: {proto_info['prototypes_per_class']}\")\nprint(f\"Prototype dimension: {proto_info['prototype_dim']}\")\nprint(\"\\nPrototype assignments:\")\nfor c in range(NUM_CLASSES):\n    class_protos = [i for i in range(proto_info['num_prototypes'])\n                   if proto_info['prototype_class_identity'][i, c] == 1]\n    print(f\"  Class {c}: Prototypes {class_protos}\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Setup Callbacks and Checkpointing\n",
    "\n",
    "**IMPORTANT:** We'll save checkpoints to Google Drive for persistence across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "import datetime\n",
    "\n",
    "# Mount Google Drive for checkpoint storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories\n",
    "checkpoint_dir = '/content/checkpoints'\n",
    "logs_dir = '/content/logs'\n",
    "!mkdir -p {checkpoint_dir}\n",
    "!mkdir -p {logs_dir}\n",
    "\n",
    "# Google Drive checkpoint directory (for persistence)\n",
    "drive_checkpoint_dir = f'/content/drive/MyDrive/protoseg_{TRAINING_MODE}_checkpoints'\n",
    "!mkdir -p {drive_checkpoint_dir}\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def create_callbacks(phase_name=\"\"):\n",
    "    \"\"\"Create callbacks for training.\"\"\"\n",
    "    phase_suffix = f\"_{phase_name}\" if phase_name else \"\"\n",
    "    \n",
    "    return [\n",
    "        # Save best model to Google Drive\n",
    "        ModelCheckpoint(\n",
    "            filepath=f'{drive_checkpoint_dir}/best_model{phase_suffix}_{timestamp}.keras',\n",
    "            monitor='val_mean_iou',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # TensorBoard logging\n",
    "        TensorBoard(\n",
    "            log_dir=f'{logs_dir}/{timestamp}{phase_suffix}',\n",
    "            histogram_freq=1,\n",
    "            write_graph=True\n",
    "        ),\n",
    "        \n",
    "        # CSV Logger\n",
    "        CSVLogger(\n",
    "            filename=f'{drive_checkpoint_dir}/training_log{phase_suffix}_{timestamp}.csv',\n",
    "            append=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "# Create callbacks based on training mode\n",
    "if TRAINING_MODE == \"single-phase\":\n",
    "    callbacks = create_callbacks()\n",
    "    \n",
    "    # Add early stopping and LR reduction for single-phase\n",
    "    callbacks.extend([\n",
    "        EarlyStopping(\n",
    "            monitor='val_mean_iou',\n",
    "            patience=10,\n",
    "            mode='max',\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_mean_iou',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            mode='max',\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    print(\"‚úì Single-phase callbacks configured!\")\n",
    "    print(f\"  - Drive backups: {drive_checkpoint_dir}\")\n",
    "    print(f\"  - TensorBoard logs: {logs_dir}\")\n",
    "    print(\"  - EarlyStopping: patience=10 epochs\")\n",
    "    print(\"  - ReduceLROnPlateau: patience=5 epochs\")\n",
    "else:\n",
    "    print(\"‚úì Multi-step callbacks will be created per phase\")\n",
    "    print(f\"  - Drive backups: {drive_checkpoint_dir}\")\n",
    "    print(f\"  - TensorBoard logs: {logs_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Train the Model\n",
    "\n",
    "**This will take several hours. Keep the browser tab active to prevent disconnection!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(f\"STARTING {TRAINING_MODE.upper()} TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANT: Keep this browser tab active to prevent disconnection!\")\n",
    "print(\"‚ö†Ô∏è Models are being saved to Google Drive automatically\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "if TRAINING_MODE == \"single-phase\":\n",
    "    # ========== SINGLE-PHASE TRAINING ==========\n",
    "    print(f\"Training for {SINGLE_PHASE_EPOCHS} epochs\")\n",
    "    print(f\"Learning rate: {SINGLE_PHASE_LR}\")\n",
    "    print()\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=SINGLE_PHASE_EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Save final model\n",
    "    model.save(f'{drive_checkpoint_dir}/final_model_{timestamp}.keras')\n",
    "    print(f\"\\n‚úì Final model saved: {drive_checkpoint_dir}/final_model_{timestamp}.keras\")\n",
    "\n",
    "else:\n",
    "    # ========== MULTI-STEP TRAINING ==========\n",
    "    \n",
    "    # Calculate epochs per phase\n",
    "    samples_per_epoch = int(NUM_VOLUMES * (1 - SPLIT_RATIO))\n",
    "    warmup_epochs = max(1, WARMUP_STEPS * BATCH_SIZE // samples_per_epoch)\n",
    "    joint_epochs = max(1, JOINT_STEPS * BATCH_SIZE // samples_per_epoch)\n",
    "    finetune_epochs = max(1, FINETUNE_STEPS * BATCH_SIZE // samples_per_epoch)\n",
    "    \n",
    "    histories = {}\n",
    "    \n",
    "    # ===== PHASE 1: WARMUP =====\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PHASE 1: WARMUP\")\n",
    "    print(\"=\" * 60)\n",
    "    model.setup_warmup_phase()\n",
    "    model.print_trainable_status()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=WARMUP_LR),\n",
    "        loss=loss_fn,\n",
    "        metrics=model.metrics\n",
    "    )\n",
    "    if USE_DIVERSITY_LOSS:\n",
    "        model.use_diversity_loss = True\n",
    "    \n",
    "    histories['warmup'] = model.fit(\n",
    "        train_generator,\n",
    "        epochs=warmup_epochs,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=create_callbacks(\"warmup\"),\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save(f'{drive_checkpoint_dir}/after_warmup_{timestamp}.keras')\n",
    "    \n",
    "    # ===== PHASE 2: JOINT TRAINING =====\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PHASE 2: JOINT TRAINING\")\n",
    "    print(\"=\" * 60)\n",
    "    model.setup_joint_training_phase()\n",
    "    model.print_trainable_status()\n",
    "    \n",
    "    # Polynomial LR decay\n",
    "    lr_schedule = keras.optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=JOINT_LR,\n",
    "        decay_steps=JOINT_STEPS,\n",
    "        end_learning_rate=JOINT_LR * 0.01,\n",
    "        power=0.9\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=loss_fn,\n",
    "        metrics=model.metrics\n",
    "    )\n",
    "    if USE_DIVERSITY_LOSS:\n",
    "        model.use_diversity_loss = True\n",
    "    \n",
    "    histories['joint'] = model.fit(\n",
    "        train_generator,\n",
    "        epochs=joint_epochs,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=create_callbacks(\"joint\"),\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save(f'{drive_checkpoint_dir}/after_joint_{timestamp}.keras')\n",
    "    \n",
    "    # ===== PHASE 3: FINE-TUNING 1 =====\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PHASE 3: FINE-TUNING 1\")\n",
    "    print(\"=\" * 60)\n",
    "    model.setup_finetuning_phase()\n",
    "    model.print_trainable_status()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=FINETUNE_LR),\n",
    "        loss=loss_fn,\n",
    "        metrics=model.metrics\n",
    "    )\n",
    "    \n",
    "    histories['finetune1'] = model.fit(\n",
    "        train_generator,\n",
    "        epochs=finetune_epochs,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=create_callbacks(\"finetune1\"),\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save(f'{drive_checkpoint_dir}/after_finetune1_{timestamp}.keras')\n",
    "    \n",
    "    # ===== PHASE 4: FINE-TUNING 2 =====\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PHASE 4: FINE-TUNING 2 (FINAL)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    histories['finetune2'] = model.fit(\n",
    "        train_generator,\n",
    "        epochs=finetune_epochs,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=create_callbacks(\"finetune2\"),\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save(f'{drive_checkpoint_dir}/final_model_{timestamp}.keras')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úì TRAINING COMPLETED!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if TRAINING_MODE == \"single-phase\":\n",
    "    # Plot single-phase training\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle('ProtoSeg3D Training Metrics (Single-Phase)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    axes[0].set_title('Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "    axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    axes[1].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mean IoU\n",
    "    axes[2].plot(history.history['mean_iou'], label='Training Mean IoU', linewidth=2)\n",
    "    axes[2].plot(history.history['val_mean_iou'], label='Validation Mean IoU', linewidth=2)\n",
    "    axes[2].set_title('Mean IoU', fontsize=14, fontweight='bold')\n",
    "    axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[2].set_ylabel('Mean IoU', fontsize=12)\n",
    "    axes[2].legend(fontsize=10)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{drive_checkpoint_dir}/training_history_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL METRICS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Best validation Mean IoU: {max(history.history['val_mean_iou']):.4f}\")\n",
    "    print(f\"Best validation Accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "    print(f\"Best validation Loss: {min(history.history['val_loss']):.4f}\")\n",
    "\n",
    "else:\n",
    "    # Plot multi-step training\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('ProtoSeg3D Multi-Step Training Metrics', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    phases = ['warmup', 'joint', 'finetune1', 'finetune2']\n",
    "    colors = ['blue', 'green', 'orange', 'red']\n",
    "    \n",
    "    for idx, (phase, color) in enumerate(zip(phases, colors)):\n",
    "        if phase in histories:\n",
    "            row = idx // 2\n",
    "            col = idx % 2\n",
    "            \n",
    "            ax = axes[row, col]\n",
    "            ax.plot(histories[phase].history['mean_iou'], label='Train IoU', color=color, linewidth=2)\n",
    "            ax.plot(histories[phase].history['val_mean_iou'], label='Val IoU', color=color, linestyle='--', linewidth=2)\n",
    "            ax.set_title(f'Phase {idx+1}: {phase.title()}', fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel('Epoch', fontsize=12)\n",
    "            ax.set_ylabel('Mean IoU', fontsize=12)\n",
    "            ax.legend(fontsize=10)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{drive_checkpoint_dir}/multistep_history_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print metrics per phase\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL METRICS PER PHASE\")\n",
    "    print(\"=\" * 60)\n",
    "    for phase in phases:\n",
    "        if phase in histories:\n",
    "            best_iou = max(histories[phase].history['val_mean_iou'])\n",
    "            print(f\"{phase.title():15s} - Best val Mean IoU: {best_iou:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úì Training history saved to Google Drive\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16: Test Prediction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample from validation set\n",
    "print(\"Loading sample for prediction...\")\n",
    "sample_x, sample_y = validation_generator[0]\n",
    "\n",
    "print(f\"Input shape: {sample_x.shape}\")\n",
    "print(f\"Label shape: {sample_y.shape}\")\n",
    "\n",
    "# Make prediction\n",
    "print(\"\\nGenerating prediction...\")\n",
    "prediction = model.predict(sample_x, verbose=0)\n",
    "print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "# Visualize middle slice\n",
    "slice_idx = D // 2  # Middle slice\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle(f'ProtoSeg3D Brain Tumor Segmentation - Slice {slice_idx}', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Input modalities\n",
    "axes[0, 0].imshow(sample_x[0, slice_idx, :, :, 0], cmap='gray')\n",
    "axes[0, 0].set_title('FLAIR', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(sample_x[0, slice_idx, :, :, 1], cmap='gray')\n",
    "axes[0, 1].set_title('T1', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(sample_x[0, slice_idx, :, :, 2], cmap='gray')\n",
    "axes[0, 2].set_title('T1ce', fontsize=12)\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Ground truth and prediction\n",
    "axes[1, 0].imshow(sample_x[0, slice_idx, :, :, 3], cmap='gray')\n",
    "axes[1, 0].set_title('T2', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(np.argmax(sample_y[0, slice_idx], axis=-1), cmap='jet', vmin=0, vmax=NUM_CLASSES-1)\n",
    "axes[1, 1].set_title('Ground Truth', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(np.argmax(prediction[0, slice_idx], axis=-1), cmap='jet', vmin=0, vmax=NUM_CLASSES-1)\n",
    "axes[1, 2].set_title('ProtoSeg Prediction', fontsize=12)\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{drive_checkpoint_dir}/prediction_visualization_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Prediction visualization saved to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 17: Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\" \" * 20 + \"TRAINING COMPLETE!\" + \" \" * 20)\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n‚úì Training mode: {TRAINING_MODE.upper()}\")\n",
    "print(f\"‚úì Your trained models are safely stored in Google Drive:\")\n",
    "print(f\"  üìÅ {drive_checkpoint_dir}/\")\n",
    "\n",
    "if TRAINING_MODE == \"single-phase\":\n",
    "    print(\"\\n‚úì Files saved:\")\n",
    "    print(f\"  - best_model_{timestamp}.keras\")\n",
    "    print(f\"  - final_model_{timestamp}.keras\")\n",
    "    print(f\"  - training_log_{timestamp}.csv\")\n",
    "    print(f\"  - training_history_{timestamp}.png\")\n",
    "else:\n",
    "    print(\"\\n‚úì Files saved:\")\n",
    "    print(f\"  - best_model_warmup_{timestamp}.keras\")\n",
    "    print(f\"  - best_model_joint_{timestamp}.keras\")\n",
    "    print(f\"  - best_model_finetune1_{timestamp}.keras\")\n",
    "    print(f\"  - best_model_finetune2_{timestamp}.keras\")\n",
    "    print(f\"  - after_warmup_{timestamp}.keras\")\n",
    "    print(f\"  - after_joint_{timestamp}.keras\")\n",
    "    print(f\"  - after_finetune1_{timestamp}.keras\")\n",
    "    print(f\"  - final_model_{timestamp}.keras\")\n",
    "    print(f\"  - training_log_*_{timestamp}.csv (per phase)\")\n",
    "    print(f\"  - multistep_history_{timestamp}.png\")\n",
    "\n",
    "print(f\"  - prediction_visualization_{timestamp}.png\")\n",
    "\n",
    "print(\"\\nüìä Model Configuration:\")\n",
    "print(f\"  - Architecture: ProtoSeg3D\")\n",
    "print(f\"  - Prototypes per class: {NUM_PROTOTYPES_PER_CLASS}\")\n",
    "print(f\"  - Total prototypes: {NUM_PROTOTYPES_PER_CLASS * NUM_CLASSES}\")\n",
    "print(f\"  - Diversity loss: {'Enabled' if USE_DIVERSITY_LOSS else 'Disabled'}\")\n",
    "print(f\"  - Training mode: {TRAINING_MODE}\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"  1. Evaluate model on test set\")\n",
    "print(\"  2. Visualize learned prototypes\")\n",
    "print(\"  3. Analyze prototype activations for interpretability\")\n",
    "print(\"  4. Compare with baseline MProtoNet3D\")\n",
    "\n",
    "print(\"\\nüíæ All important files are backed up to Google Drive!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# List all saved files\n",
    "print(\"\\nFiles in Google Drive checkpoint directory:\")\n",
    "!ls -lh {drive_checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Launch TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to launch TensorBoard\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {logs_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Download Files Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download files to your computer\n",
    "# from google.colab import files\n",
    "# files.download(f'{drive_checkpoint_dir}/final_model_{timestamp}.keras')\n",
    "# files.download(f'{drive_checkpoint_dir}/prediction_visualization_{timestamp}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Notes and Tips\n\n### ProtoSeg3D Model Architecture\n- **Interpretable**: Uses prototype-based learning\n- **Encoder**: Custom 3D CNN with isotropic pooling (2√ó2√ó2)\n- **ASPP 3D**: Multi-scale context with atrous convolutions (rates: 1, 2, 4, 8)\n- **Prototypes**: 128-dimensional learned representations for each class\n- **Diversity Loss**: Jeffrey's divergence-based (graph-compatible with @tf.function)\n- **Multi-step Training**: Improved performance (+3-5% mIoU)\n\n### Preprocessing Details\n- **Method**: Center cropping only (no resizing)\n- **Original**: 155 √ó 240 √ó 240 (D√óH√óW)\n- **Preprocessed**: 128 √ó 160 √ó 192 (D√óH√óW)\n- **Benefits**: Preserves original resolution, avoids blurring small tumor labels\n\n### Training Modes\n\n**Single-Phase:**\n- Faster: ~10-12 hours\n- Simpler: One training phase\n- Expected mIoU: 0.58-0.63\n\n**Multi-Step (Recommended):**\n- Phase 1: Warmup - freeze encoder, train ASPP + prototypes\n- Phase 2: Joint training - train all except FC layer\n- Phase 3-4: Fine-tuning - train FC layer only\n- Better results: +3-5% mIoU improvement\n- Better prototype quality and interpretability\n- Longer: ~14 hours\n\n### Technical Details\n\n**Diversity Loss Implementation:**\n- Uses `@tf.function` decorator for TensorFlow graph mode compatibility\n- Works with prototype similarities (converted from distances)\n- Automatically downsamples ground truth labels to match activation resolution\n- Uses `tf.while_loop` and `tf.cond` for graph-compatible control flow\n- Class-specific: Only considers locations where each class appears\n- No Python control flow issues during training\n\n**Architecture Flow:**\n```\nInput: (B, 128, 160, 192, 4)\n  ‚Üì Encoder (isotropic pooling)\nFeatures: (B, 16, 20, 24, 128)\n  ‚Üì ASPP 3D\nFeatures: (B, 16, 20, 24, 128)\n  ‚Üì Feature Projection\nFeatures: (B, 16, 20, 24, 128)\n  ‚Üì Prototype Layer\nSimilarities: (B, 16, 20, 24, 28)\n  ‚Üì FC Layer\nLogits: (B, 16, 20, 24, 4)\n  ‚Üì Trilinear Upsample\nOutput: (B, 128, 160, 192, 4)\n```\n\n**Why Graph Mode Matters:**\n- `model.fit()` uses graph mode for better performance\n- Graph mode requires TensorFlow operations (not Python control flow)\n- `@tf.function` automatically converts Python code to graph operations\n- This enables faster training and better GPU utilization\n\n### Loading Trained Models\n\n```python\nfrom model_protoseg import ProtoSeg3D\nimport tensorflow as tf\n\n# Load model\nmodel = tf.keras.models.load_model(\n    'path/to/model.keras',\n    custom_objects={'ProtoSeg3D': ProtoSeg3D}\n)\n\n# Get prototype information\nproto_info = model.get_prototype_info()\nprint(f\"Total prototypes: {proto_info['num_prototypes']}\")\n```\n\n### Resuming Multi-Step Training\n\nIf your session disconnects during multi-step training, you can resume from the last saved checkpoint:\n\n```python\nfrom model_protoseg import ProtoSeg3D\n\n# Load checkpoint from specific phase\ncheckpoint_path = f'{drive_checkpoint_dir}/after_warmup_{timestamp}.keras'\nmodel = tf.keras.models.load_model(\n    checkpoint_path,\n    custom_objects={'ProtoSeg3D': ProtoSeg3D}\n)\n\n# Continue with next phase\nmodel.setup_joint_training_phase()\n# ... continue training\n```\n\n### Troubleshooting\n\n**Issue: \"OperatorNotAllowedInGraphError\"**\n- **Solution**: This has been fixed in `losses_protoseg.py` with `@tf.function` decorator\n- If you still see this error, make sure you pulled the latest version from GitHub\n- The diversity loss function is now fully graph-compatible\n\n**Issue: \"Out of memory\" during training**\n- **Solution**: Reduce batch size from 2 to 1\n```python\nBATCH_SIZE = 1  # Instead of 2\n```\n- Note: With new dimensions (128√ó160√ó192), memory usage is higher than old (96√ó160√ó160)\n- Consider using Colab Pro for more GPU memory\n\n**Issue: Training stuck or very slow**\n- Check GPU is enabled: Runtime ‚Üí Change runtime type ‚Üí GPU\n- Monitor GPU usage: `!nvidia-smi`\n- Check if disk is full: `!df -h /content`\n\n**Issue: Session disconnected**\n- Colab Free: 12-hour limit, Colab Pro: 24-hour limit\n- Keep browser tab active\n- Models auto-saved to Google Drive every epoch\n- Resume from last checkpoint (see above)\n\n### Performance Expectations\n\nFrom ProtoSeg paper:\n- Multi-step training improves mIoU by ~3-5% over single-phase\n- Better prototype diversity with diversity loss enabled\n- More interpretable predictions\n\nExpected for BraTS 2020:\n- ProtoSeg3D (single-phase): mIoU 0.58-0.63\n- ProtoSeg3D (multi-step): mIoU 0.62-0.68\n- Trade-off: ~5% lower than MProtoNet3D, but much more interpretable\n\n### Session Management\n- **Colab Free**: 12-hour session limit\n- **Colab Pro**: 24-hour session limit\n- Keep browser tab active to prevent disconnection\n- All checkpoints are saved to Google Drive automatically\n\n### References\n- ProtoSeg paper: \"ProtoSeg: Interpretable Semantic Segmentation with Prototypical Parts\" (WACV 2023)\n- Jeffrey's Divergence: Symmetrized KL divergence for measuring distribution similarity\n- Documentation: See PROTOSEG_ADAPTATION.md, MULTISTEP_TRAINING.md in repository\n- GitHub Issues: Report problems at your repository's issues page"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}